{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook é uma adaptação para uso no ambiente Google Colab do notebook **notebook_02.ipynb** fornecido como material complementar do livro Inteligência Artificial: Uma Abordagem de Aprendizado de Máquina|FACELI, Katti; LORENA, Ana C.; GAMA, João; AL, et. Tendo sido desenvolvido originalmente por: Renato Moraes Silva."
      ],
      "metadata": {
        "id": "V8kC3Anvq93I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de iniciar este notebook, salve o arquivo do conjunto de dados iris (iris1.csv) em um diretório local na sua máquina"
      ],
      "metadata": {
        "id": "-owHGMOtr96U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# O código abaixo monta um drive no Google colab para que você possa fazer o upload do arquivo de dados iris da sua máquina.\n",
        "\n",
        "# após executar está celula, escolha o arquivo iris1.csv que você salvou na sua máquina\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "UnnnOe6sX8Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwMK_LVc6XgR"
      },
      "source": [
        "## Introdução\n",
        "\n",
        "Neste notebook, além dos algoritmos utilizados no notebook da semana passada (K-NN e Naive Bayes), o algoritmo SVM (Support Vector Machine) e o algoritmo de indução de árvore de decisão também serão treinados e testados para classificação do conjunto de dados iris. Os resultados de desempenho em termos de tempo de execução, e taxa de acertos (acurácia), serão analisados de forma similiar ao que foi feito no notebook da semana anterior, agora juntamente com os resultados para o k-NN e Naive Bayes. Também geraremos a  visualiação da árvore de decisão induzida . Ao final, realizaremos outras medidas de desempenho, além da geração da matriz de confusão relativa a cada um dos resultados de predição obtidos pelos modelos.\n",
        "\n",
        "Os conceitos apresentados neste notebook fazem referência ao conteúdo abordado nos Capítulos **6 (Métodos Simbólicos)** e **8 (Métodos de Maximização de Márgens)** e **10 (Avaliação de Modelos Preditivos)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_jDm29g6XgU"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np # importa a biblioteca usada para trabalhar com vetores e matrizes\n",
        "import pandas as pd # importa a biblioteca usada para trabalhar com dataframes e análise de dados\n",
        "import sklearn as skl # importa o sckit-learn\n",
        "import time # sera usada para calcular o tempo de execucao dos metodos de classificacao\n",
        "\n",
        "from sklearn import model_selection \n",
        "from sklearn import naive_bayes # necessario para usar o metodo naive Bayes\n",
        "from sklearn import tree # necessario para usar arvores de decisao\n",
        "from sklearn import svm # necessario para usar o metodo SVM\n",
        "from sklearn import neighbors # necessario para usar o metodo KNN\n",
        "from sklearn import metrics # necessario para obter o desempenho da classificacao\n",
        "\n",
        "# bibliotecas para geração de gráficos\n",
        "import graphviz # usado para realizar a representação gráfica de umar árvore de decisão\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "\n",
        "print('Bibliotecas carregadas com sucesso')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu6NI88s6XgV"
      },
      "source": [
        "Vamos carregar os dados do arquivo "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y5vtnrSR6XgW"
      },
      "outputs": [],
      "source": [
        "# importa o arquivo e guarda em um dataframe do Pandas\n",
        "df_dataset = pd.read_csv( 'iris1.csv', sep=',', index_col=None) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1KrQwz36XgW"
      },
      "source": [
        "Por questões didáticas, vamos realizar os experimentos considerando apenas os atributos largura (*SepalWidthCm*) e comprimento da sépala (*SepalLengthCm*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sn0cCn_n6XgX"
      },
      "outputs": [],
      "source": [
        "# remove as colunas que não serão usadas \n",
        "df_dataset = df_dataset.drop(columns=['Id','PetalLengthCm','PetalWidthCm'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjyIlTSy6XgX"
      },
      "source": [
        "Vamos plotar os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwyjSiRY6XgY"
      },
      "outputs": [],
      "source": [
        "# scatter plot\n",
        "sns.lmplot(x='SepalLengthCm', y='SepalWidthCm', data=df_dataset, \n",
        "           fit_reg=False,   # Sem linha de regressão\n",
        "           hue='Species')   # Cores diferentes por classe\n",
        "\n",
        "# cria um título para o gráfico\n",
        "plt.title('SepalLengthCm vs SepalWidthCm')\n",
        "\n",
        "# mostra o gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iPuqFat6XgY"
      },
      "source": [
        "Armazena os dados dentro de uma matriz e as classes dentro de um vetor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SmC3Em996XgY"
      },
      "outputs": [],
      "source": [
        "# obtém os valores das n-1 primeiras colunas e guarda em uma matrix X\n",
        "X = df_dataset[['SepalLengthCm','SepalWidthCm']].values \n",
        "\n",
        "# obtém os valores da ultima coluna e guarda em um vetor Y\n",
        "Y = df_dataset[['Species']].values \n",
        "Y = np.ravel( Y ) # converte em um vetor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3FJQ84Q6XgZ"
      },
      "source": [
        "Vamos dividir a base de dados em duas partições (treino e teste), mantendo a distribuição original de dados de cada classe em cada partição. Os primeiros $70\\%$ dos dados de cada classe irão compor o conjunto de treinamento, enquanto o restante  comporá os dados de teste. Para isso, usaremos a função `sklearn.model_selection.StratifiedShuffleSpli`. \n",
        "\n",
        "A função `sklearn.model_selection.StratifiedShuffleSplit` pode ser usada para gerar $n$ particionamentos estratificados. A quantidade de particionamentos é definida pelo parâmetro `n_splits`.  Vamos usar apenas um particionamento de treino e de teste. Por isso, iremos setar o parâmetro `n_splits` com valor 1. \n",
        "\n",
        "É importante que as partições de treinamento e teste sejam geradas de forma aleatória. Para que toda a execução gere o mesmo resultado, vamos usar uma semente para a função de geração de números aleatórios, setando um valor qualquer para o parâmetro `random_state`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N3wiltH6XgZ"
      },
      "outputs": [],
      "source": [
        "# gera uma divisão dos dados em treino e teste, com 70% de dados para o treinamento e 30% para teste\n",
        "cv = skl.model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=2020)\n",
        "\n",
        "# retorna os índices de treino e teste\n",
        "train_index, test_index = list( cv.split(X, Y) )[0]\n",
        "\n",
        "# retorna as partições de treino e teste de acordo com os índices\n",
        "X_train, X_test = X[train_index, :], X[test_index, :];\n",
        "Y_train, Y_test = Y[train_index], Y[test_index];\n",
        "\n",
        "print('Qtd. dados de treinamento: %d (%1.2f%%)' %(X_train.shape[0], (X_train.shape[0]/X.shape[0])*100) )\n",
        "print('Qtd. de dados de teste: %d (%1.2f%%)' %(X_test.shape[0], (X_test.shape[0]/X.shape[0])*100) )\n",
        "\n",
        "# imprime a porcentagem de dados de treinamento de cada classe\n",
        "print(\"\\nQtd. de dados de cada classe (treinamento)\")\n",
        "cTrain, counts_cTrain = np.unique(np.sort(Y_train), return_counts=True)\n",
        "for i in range( len(cTrain) ):\n",
        "    print('\\tClasse %s: %d (%1.2f%%)' %( cTrain[i],counts_cTrain[i],(counts_cTrain[i]/len(Y_train))*100 ) )\n",
        "\n",
        "# imprime a porcetagem de dados de teste de cada classe\n",
        "print(\"\\nQtd. de dados de cada classe (teste)\")\n",
        "cTest, counts_cTest = np.unique(np.sort(Y_test), return_counts=True)\n",
        "for i in range( len(cTrain) ):\n",
        "    print('\\tClasse %s: %d (%1.2f%%)' %( cTest[i],counts_cTest[i],(counts_cTest[i]/len(Y_test))*100 ) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDyM_koZ6XgZ"
      },
      "source": [
        "Vamos normalizar os valores dos atributos para que fiquem com média igual a zero e desvio padrão igual a um. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PMR-j2Cg6Xga"
      },
      "outputs": [],
      "source": [
        "# normaliza os valores dos atributos para que fiquem com media igual a zero e desvio padrao igual a um\n",
        "scaler = skl.preprocessing.StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Qo7gH06Xga"
      },
      "source": [
        "Agora que separamos os dados em duas partições, podemos treinar os algoritmos de classicação K-NN, Naive Bayes, SVM, e o algoritmo de indução de árvore de decisão  utilizando a partição de treinamento,  e testar utilizando a partição de teste.  \n",
        "\n",
        "A função **perform_experiment_mod** realiza o treinamento e teste de classificadores, além disso ela também calcula o tempo gasto pelos algoritmos no treinamento e teste, além de fornecer a medida de acurácia. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4I8KH-c0DV6M"
      },
      "outputs": [],
      "source": [
        "def perform_experimen_mod(dataset, target, methodName):\n",
        "    \"\"\"\n",
        "    Função usada para executar os experimentos\n",
        "    \n",
        "    Parametros:\n",
        "    -----------\n",
        "    dataset: array\n",
        "        É um array com dimensão \"m x n\", onde \"m\" é o número de amostras e \"n\" é o número de atributos\n",
        "\n",
        "    target: array\n",
        "        É uma lista ou um vetor contendo as classes de cada amostra\n",
        "    \n",
        "    methodName: string\n",
        "    \n",
        "        Um nome usado para identificar o método.\n",
        "\n",
        "        'G.NB': Naive Bayes Gaussiano\n",
        "        'KNN': k-nearest neighbors \n",
        "        'SVM': Support vector machines\n",
        "        'DT': Decision trees        \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    resultados=[] # cria uma lista vazia para guardar os resultados obtidos \n",
        "  \n",
        "    auxResults=[]\n",
        "\n",
        "\n",
        "    x_train, x_test = X_train, X_test\n",
        "    y_train, y_test =  Y_train,  Y_test\n",
        " \n",
        "    # inicia um timer para analisar o tempo levado para o treinamento e teste\n",
        "    startTime = time.time() \n",
        "            \n",
        "    #define o classificador que será utilizados\n",
        "    if methodName == 'G.NB': # Naive Bayes Gaussiano\n",
        "    # inicia o classificador\n",
        "      classifier = skl.naive_bayes.GaussianNB()  \n",
        "    elif methodName == 'KNN': # K-Vizinhos mais próximos\n",
        "    # inicia o classificador com os parâmetros default do Scikit\n",
        "      classifier  = skl.neighbors.KNeighborsClassifier()\n",
        "    elif methodName == 'DT': # Árvores de decisão \n",
        "        # inicia o classificador\n",
        "        classifier = skl.tree.DecisionTreeClassifier(criterion='entropy')\n",
        "    elif methodName == 'SVM':\n",
        "        # inicia o classificador com os parâmetros default do Scikit\n",
        "        classifier = skl.svm.SVC()\n",
        "        \n",
        "    # treina o classificador com os dados de treinameto\n",
        "    classifier.fit(x_train, y_train) \n",
        "        \n",
        "    # classifica os dados de teste\n",
        "    y_pred = classifier.predict(x_test) \n",
        "\n",
        "    # obtem a acuracia\n",
        "    acuracia = metrics.accuracy_score(y_test, y_pred)         \n",
        "\n",
        "    # calcula o tempo despendido no treinamento e no teste\n",
        "    tempo = time.time() - startTime\n",
        "\n",
        "    # guarda o classificador dentro de resultados\n",
        "    auxResults=({'classificador': classifier})\n",
        "    \n",
        "    # acrescenta o tempo aos resultados\n",
        "    auxResults.update({'tempo': tempo})\n",
        "\n",
        "\n",
        "    # acrescenta a acuracia dentro de resultados\n",
        "    auxResults.update({'acuracia': acuracia})\n",
        "\n",
        "    # guarda o classificador dentro de resultados\n",
        "    auxResults.update({'classifier': classifier})\n",
        "\n",
        "# adiciona os resultados  na lista de resultados\n",
        "    resultados.append( auxResults ) \n",
        "    return resultados\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos executar o experimento para obtenção dos resultados para os algoritmos. "
      ],
      "metadata": {
        "id": "G0H8XjIRWM9O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LBthcafsDV6M"
      },
      "outputs": [],
      "source": [
        "metodos = ['G.NB','KNN','DT','SVM'] \n",
        "\n",
        "# cria uma lista vazia para guardar as informacoes retornadas em cada experimentos\n",
        "resultadosMetodos = []\n",
        "\n",
        "# para cada método da lista de métodos, executa um experimento com os parâmetros informados    \n",
        "for methodName in metodos:\n",
        "    resultados = perform_experimen_mod(X, Y, methodName)\n",
        "    resultadosMetodos.append(resultados)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que o  KNN  continua sendo o algoritmo mais demorado. Isto se deve, ao que já foi mencionado no notebook da semana anterior, de que o cálculo da vizinhança de cada amostra realizado pelo K-NN ser computacionalmente custoso."
      ],
      "metadata": {
        "id": "qSWK5BIzW1pV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aB_FIKQDV6N"
      },
      "outputs": [],
      "source": [
        "\n",
        "tempoMetodo = {}\n",
        "\n",
        "for i, methodName in enumerate(metodos):\n",
        "    \n",
        "    auxTempo = [ d['tempo'] for d in resultadosMetodos[i] ] \n",
        "    \n",
        "    tempoMetodo.update({methodName: np.mean(auxTempo)})\n",
        " \n",
        "# cria  um dataframe com os tempos de cada metodo \n",
        "df_tempo = pd.DataFrame(tempoMetodo.items(), columns=['Metodo', 'Tempo'])\n",
        "\n",
        "# definindo o tamanho da figura \n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "# cria um gráfico de barras \n",
        "sns.barplot(x=\"Metodo\", y=\"Tempo\", data=df_tempo)\n",
        "\n",
        "# mostra o gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos verificar a acurácia dos modelos gerados"
      ],
      "metadata": {
        "id": "lQyC0lmWW96q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afx8ltpVDV6N"
      },
      "outputs": [],
      "source": [
        "accMetodo = {}\n",
        "\n",
        "for i, methodName in enumerate(metodos):\n",
        "    \n",
        "    auxAcc = [ d['acuracia'] for d in resultadosMetodos[i] ] \n",
        "    \n",
        "    accMetodo.update({methodName: np.mean(auxAcc)})\n",
        " \n",
        "# cria  um dataframe com os tempos de cada metodo \n",
        "df_acc = pd.DataFrame(accMetodo.items(), columns=['Metodo', 'Acuracia'])\n",
        "\n",
        "# definindo o tamanho da figura \n",
        "plt.figure(figsize=(10,8))\n",
        "\n",
        "# cria um gráfico de barras \n",
        "sns.barplot(x=\"Metodo\", y=\"Acuracia\", data=df_acc)\n",
        "\n",
        "# mostra o gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCohHBD_6Xga"
      },
      "source": [
        "O a função abaixo é utilizada para plotagem da região de decisão correspondente à classificação dos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pYRHKzFA6Xgb"
      },
      "outputs": [],
      "source": [
        "def plota_superficieDecisao(methodName, X, Y, ax, title = \"\"):\n",
        "    h = .02  # tamanho do passo da malha (mesh)\n",
        "\n",
        "    # cria uma malha (mesh)\n",
        "    x_min, x_max = X[:, 0].min() - 0.3, X[:, 0].max() + 0.3\n",
        "    y_min, y_max = X[:, 1].min() - 0.3, X[:, 1].max() + 0.3\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "     \n",
        "\n",
        "    #define o classificador que será utilizados\n",
        "    if methodName == 'G.NB': # Naive Bayes Gaussiano\n",
        "    # inicia o classificador\n",
        "      classifier = skl.naive_bayes.GaussianNB()  \n",
        "    elif methodName == 'KNN': # K-Vizinhos mais próximos\n",
        "    # inicia o classificador com os parâmetros default do Scikit\n",
        "      classifier  = skl.neighbors.KNeighborsClassifier()\n",
        "    elif methodName == 'DT': # Árvores de decisão \n",
        "        # inicia o classificador\n",
        "        classifier = skl.tree.DecisionTreeClassifier(criterion='entropy')\n",
        "    elif methodName == 'SVM':\n",
        "        # inicia o classificador com os parâmetros default do Scikit\n",
        "        classifier = skl.svm.SVC()\n",
        "        \n",
        "\n",
        "    # treina o classificador com os dados de treinameto\n",
        "    classifier.fit(X_train, Y_train) \n",
        "    \n",
        "\n",
        "\n",
        "    # obtem a predicao\n",
        "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # converte os valores do vetor para indices\n",
        "    Z2 = np.unique(Z, return_inverse=True)[1]\n",
        "\n",
        "    # plota a superficie de decisao\n",
        "    Z2 = Z2.reshape(xx.shape)\n",
        "    ax.contourf(xx, yy, Z2, cmap=plt.cm.Paired, alpha=.4)\n",
        "\n",
        "    # converte os valores do vetor para indices\n",
        "    Y2 = np.unique(Y, return_inverse=True)[1]\n",
        "\n",
        "    # plota os dados de treinamento\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=Y2, edgecolor='k', s=50)\n",
        "    \n",
        "    ax.set_xlim(xx.min(), xx.max())\n",
        "    ax.set_ylim(yy.min(), yy.max())\n",
        "    ax.set_title(title, fontsize='large')\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos dar uma olhada na superfície de decisão aprendida pelos modelos."
      ],
      "metadata": {
        "id": "Qd4WuUpXfeR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a quantidade de linhas e colunas e o tamanho da figura\n",
        "nrows = 3; ncols=2; \n",
        "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8*ncols, 8*nrows))\n",
        "\n",
        "# apaga a ultima figura \n",
        "fig.delaxes(axs[2,0]) #The indexing is zero-based here\n",
        "fig.delaxes(axs[2,1])\n",
        "# converte o array em um vetor\n",
        "axs = np.concatenate(axs)\n",
        "    \n",
        "for i, methodName in enumerate(metodos):\n",
        "    \n",
        "    auxClassificador = [ d['classifier'] for d in resultadosMetodos[i] ]\n",
        "    \n",
        "    for train_index, test_index in cv.split(X, Y):\n",
        "\n",
        "        X_train, X_test = X[train_index, :], X[test_index, :];\n",
        "        Y_train, Y_test = Y[train_index], Y[test_index];\n",
        "        \n",
        "        if methodName in ['G.NB', 'SVM', 'DT', 'KNN']:\n",
        "            \n",
        "            # normaliza os valores dos atributos para que fiquem com media igual a zero e desvio padrao igual a um\n",
        "            scaler = skl.preprocessing.StandardScaler().fit(X_train)\n",
        "            X_train = scaler.transform(X_train)\n",
        "            X_test = scaler.transform(X_test)\n",
        "    \n",
        "        plota_superficieDecisao(methodName, X_test, Y_test, axs[i], title = methodName)\n",
        "        \n",
        "        break"
      ],
      "metadata": {
        "id": "GHdJC31EjmcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualização da Árvore de Decisão**\n",
        "\n",
        "Abaixo vamos gerar a visualização da árvore de decisão gerada.\n",
        "\n",
        "Obs1.Em cada nó da árvore de decisão é apresentado (como exemplo seja o primeiro nó):\n",
        "\n",
        "*o critério condicional para a divisão (e.g. SepalLengthCm < -0.151 )\n",
        "\n",
        "*o valor da entropia do conjunto (e.g. entropy = 1.585)\n",
        "\n",
        "*o número de exemplos no conjunto.(e.g. samples = 105)\n",
        "\n",
        "*o numero de exemplos de cada classe presente no conjunto.(e.g. [35, 35, 35] ->35 Iris-setosa, 35 Iris-versicolor, 35 Iris-Virginica)\n",
        "\n",
        "*a classe predominante no conjunto\n",
        "\n",
        "Obs2. Aparecem valores negativos nos valores das dimensões das sépalas ('NormSepalLengthCm','NormSepalWidthCm'), porque o conjunto de dados sofreu regularização antes do processamento."
      ],
      "metadata": {
        "id": "ljqqCJCorEOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = skl.tree.DecisionTreeClassifier(criterion='entropy')\n",
        "# treina o classificador com os dados de treinameto\n",
        "classifier.fit(X_train, Y_train)\n",
        "#representação gráfica da árvore de decisão\n",
        "dot_data = tree.export_graphviz(classifier, out_file=None, \n",
        "feature_names=['NormSepalLengthCm','NormSepalWidthCm'], \n",
        "class_names=['Iris-setosa','Iris-versicolor' ,'Iris-virginica' ],\n",
        "filled=True, rounded=True,  \n",
        "special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph "
      ],
      "metadata": {
        "id": "jk_7qy-Qhb_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medidas de desempenho\n",
        "\n",
        "Vamos calcular o desempenho dos algoritmos de classificação (Capítulo 10 - Avaliação de Modelos Preditivos). Algumas medidas de desempenho (*e.g.*, acurácia) retornam um valor global de desempenho, enquanto que outras (*e.g.*, precisão, revocação e F-medida) retornam um valor que pode variar dependendo de qual classe é considerada como positiva (classe alvo do problema). Supondo que em um determinado problema, a classe $c_1$ seja considerada a classe positiva, as seguintes medidas de desempenho podem ser calculadas:\n",
        "\n",
        "* $\\displaystyle \\text{acurácia} =\\frac{vp_1+vn_1}{vp_1+vn_1+fp_1+fn_1} = \\frac{\\text{Qtd. de predições corretas}}{\\text{Qtd. de amostras}};$\n",
        "\n",
        "* $\\displaystyle \\text{revocação} =  \\frac{vp_1}{vp_1+fn_1} \\text{;} $\n",
        "\n",
        "* $\\displaystyle \\text{precisão} = \\frac{vp_1}{vp_1+fp_1}; $\n",
        "\n",
        "* $\\displaystyle \\text{F-medida} = 2 \\times \\frac{\\text{precisão} \\times\\text{revocação}}{\\text{precisão}+\\text{revocação}}.$\n",
        "\n",
        "Para problemas binários sem uma classe-alvo ou para problemas multiclasse, normalmente são utilizadas medidas de desempenho que consideram a média entre os resultados relativos a cada classe do problema. As duas principais estratégias para obter a média de desempenho entre as classes são a média macro e a média micro. A média macro considera que todas as classes possuem a mesma importância. Por outro lado, na média micro, o resultado final é dominado pelas classes mais frequentes, o que pode gerar um desempenho superestimado quando as classes são muito desbalanceadas. Abaixo, são apresentadas algumas medidas de desempenho calculadas por meio dessas duas estratégias.\n",
        "\n",
        "* Medidas baseadas na média macro:\n",
        " - $ \\displaystyle \\text{macro revocação} = \\frac{1}{{|\\mathcal{C}|}} \\times \\sum_{j=1}^{{|\\mathcal{C}|}} \\frac{vp_j}{vp_j+fn_j}$;\n",
        "\t\t\n",
        " - $ \\displaystyle \\text{macro precisão} = \\frac{1}{{|\\mathcal{C}|}} \\times \\sum_{j=1}^{{|\\mathcal{C}|}} \\frac{vp_j}{vp_j+fp_j}$;\n",
        "\t\t\n",
        " - $ \\displaystyle \\text{macro F-medida} = 2 \\times \\frac{\\text{macro precisão} \\times\\text{macro revocação}}{\\text{macro precisão}+\\text{macro revocação}}$.\n",
        "\n",
        "\n",
        "* Medidas baseadas na média micro:\n",
        " - $ \\displaystyle \\text{micro revocação} = \\frac{\\sum_{j=1}^{{|\\mathcal{C}|}} vp_j}{\\sum_{j=1}^{{|\\mathcal{C}|}} vp_j+fn_j}$;\n",
        "\n",
        " - $ \\displaystyle \\text{micro precisão} = \\frac{\\sum_{j=1}^{{|\\mathcal{C}|}} vp_j}{\\sum_{j=1}^{{|\\mathcal{C}|}} vp_j+fp_j}$; \n",
        "\n",
        " - $ \\displaystyle \\text{micro F-medida} = 2 \\times \\frac{\\text{micro precisão} \\times\\text{micro revocação}}{\\text{micro precisão}+\\text{micro revocação}}$.\n",
        "\n",
        "Na função abaixo, será gerado um relatório com as principais medidas de desempenho. Será calculada a **precisão**, **revocação** e **F-medida** para cada uma das classes do problema. Adicionalmente, será calculada a **acurácia**, **macro** e **micro precisão**, **macro** e **micro revocação** e, por fim, a **macro** e **micro F-medida**."
      ],
      "metadata": {
        "id": "9tnahT4vFMv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relatorioDesempenho(Y_test, Y_pred, classes, imprimeRelatorio=False):\n",
        "  \"\"\"\n",
        "  Funcao usada calcular as medidas de desempenho da classificação.\n",
        "  \n",
        "  Parametros\n",
        "  ----------   \n",
        "    \n",
        "  classes: classes do problema\n",
        "  \n",
        "  imprimeRelatorio: variavel booleana que indica se o relatorio de desempenho\n",
        "                    deve ser impresso ou nao. \n",
        "     \n",
        "  Retorno\n",
        "  -------\n",
        "  resultados: variavel do tipo dicionario (dictionary). As chaves\n",
        "              desse dicionario serao os nomes das medidas de desempenho; os valores\n",
        "              para cada chave serao as medidas de desempenho calculadas na funcao.\n",
        "              \n",
        "              Mais especificamente, o dicionario devera conter as seguintes chaves:\n",
        "              \n",
        "               - acuracia: valor entre 0 e 1 \n",
        "               - revocacao: um vetor contendo a revocacao obtida em relacao a cada classe\n",
        "                            do problema\n",
        "               - precisao: um vetor contendo a precisao obtida em relacao a cada classe\n",
        "                            do problema\n",
        "               - fmedida: um vetor contendo a F-medida obtida em relacao a cada classe\n",
        "                            do problema\n",
        "               - revocacao_macroAverage: valor entre 0 e 1\n",
        "               - precisao_macroAverage: valor entre 0 e 1\n",
        "               - fmedida_macroAverage: valor entre 0 e 1\n",
        "               - revocacao_microAverage: valor entre 0 e 1\n",
        "               - precisao_microAverage: valor entre 0 e 1\n",
        "               - fmedida_microAverage: valor entre 0 e 1\n",
        "  \"\"\"\n",
        "\n",
        "  # obtem a quantidade de classes\n",
        "  nClasses = len(classes)\n",
        "\n",
        "  # obtem a acuracia\n",
        "  acuracia = metrics.accuracy_score(Y_test, Y_pred)\n",
        "    \n",
        "  # inicializa as medidas de desempenho \n",
        "  revocacao = np.zeros( len(classes) )\n",
        "  precisao = np.zeros( len(classes) )\n",
        "  fmedida = np.zeros( len(classes) )\n",
        "    \n",
        "  # calcula a medida de desempenho para cada classe individualmente\n",
        "  for i in range( len(classes) ):\n",
        "    \n",
        "      # transforma o problema multiclasse em binário, apenas para calcular o desempenho individual da classe i\n",
        "      auxY_test = np.zeros( len(Y_test) ) # inicializa o vetor de classes binárias com 0\n",
        "      auxY_pred = np.zeros( len(Y_pred) ) # inicializa o vetor de classes binárias com 0\n",
        "      auxY_test[Y_test==classes[i]] = 1 # onde a classe for igual a classe[i], recebe valor 1\n",
        "      auxY_pred[Y_pred==classes[i]] = 1 # onde a classe for igual a classe[i], recebe valor 1\n",
        "        \n",
        "      revocacao[i] = metrics.recall_score(auxY_test, auxY_pred, pos_label=1) # revocacao\n",
        "      precisao[i] = metrics.precision_score(auxY_test, auxY_pred, pos_label=1) # precisao\n",
        "      fmedida[i] = metrics.f1_score(auxY_test, auxY_pred, pos_label=1) # f-medida \n",
        "  \n",
        "\n",
        "  revocacao_microAverage =  metrics.recall_score(Y_test, Y_pred, average='micro')\n",
        "  precisao_microAverage = metrics.precision_score(Y_test, Y_pred, average='micro')\n",
        "  fmedida_microAverage = metrics.f1_score(Y_test, Y_pred, average='micro')\n",
        "\n",
        "  revocacao_macroAverage =  metrics.recall_score(Y_test, Y_pred, average='macro')\n",
        "  precisao_macroAverage = metrics.precision_score(Y_test, Y_pred, average='macro')\n",
        "  fmedida_macroAverage = metrics.f1_score(Y_test, Y_pred, average='macro')\n",
        "  \n",
        "  \n",
        "  # imprime os resultados para cada classe\n",
        "  if imprimeRelatorio:\n",
        "        \n",
        "      print('\\n\\tRevocacao   Precisao   F-medida   Classe')\n",
        "      for i in range(nClasses):\n",
        "        print('\\t%1.3f       %1.3f      %1.3f      %s' % (revocacao[i], precisao[i], fmedida[i],classes[i] ) )\n",
        "    \n",
        "      print('\\t------------------------------------------------');\n",
        "      \n",
        "      #imprime as médias\n",
        "      print('\\t%1.3f       %1.3f      %1.3f      Média macro' % (revocacao_macroAverage, precisao_macroAverage, fmedida_macroAverage) )\n",
        "      print('\\t%1.3f       %1.3f      %1.3f      Média micro\\n' % (revocacao_microAverage, precisao_microAverage, fmedida_microAverage) )\n",
        "    \n",
        "      print('\\tAcuracia: %1.3f' %acuracia)\n",
        "      \n",
        "  # armazena os resultados em uma estrutura tipo dicionario\n",
        "  resultados = {'revocacao': revocacao, 'acuracia': acuracia, 'precisao':precisao, 'fmedida':fmedida}\n",
        "  resultados.update({'revocacao_macroAverage':revocacao_macroAverage, 'precisao_macroAverage':precisao_macroAverage, 'fmedida_macroAverage':fmedida_macroAverage})\n",
        "  resultados.update({'revocacao_microAverage':revocacao_microAverage, 'precisao_microAverage':precisao_microAverage, 'fmedida_microAverage':fmedida_microAverage})\n",
        "\n",
        "  return resultados \n"
      ],
      "metadata": {
        "id": "AWS1Smt8_K0l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matriz de confusão\n",
        "\n",
        "A maioria das medidas de desempenho pode ser calculada a partir da matriz de confusão. O código abaixo, irá gerar as predições que serão utilizadas na matriz de confusão para um modelo selecionado"
      ],
      "metadata": {
        "id": "dFl3dCCwFnPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def confusao(methodName):\n",
        "   #define o classificador que será utilizados\n",
        "    if methodName == 'G.NB': # Naive Bayes Gaussiano\n",
        "    # inicia o classificador\n",
        "      classifier = skl.naive_bayes.GaussianNB()  \n",
        "    elif methodName == 'KNN': # K-Vizinhos mais próximos\n",
        "    # inicia o classificador com os parâmetros default do Scikit\n",
        "      classifier  = skl.neighbors.KNeighborsClassifier()\n",
        "    elif methodName == 'DT': # Árvores de decisão \n",
        "        # inicia o classificador\n",
        "        classifier = skl.tree.DecisionTreeClassifier(criterion='entropy')\n",
        "    elif methodName == 'SVM':\n",
        "        # inicia o classificador com os parâmetros default do Scikit\n",
        "        classifier = skl.svm.SVC()\n",
        "        \n",
        "\n",
        "    # treina o classificador com os dados de treinameto\n",
        "    classifier.fit(X_train, Y_train)   \n",
        "    # classifica os dados de teste\n",
        "    Y_pred = classifier.predict(X_test)\n",
        "    return Y_pred"
      ],
      "metadata": {
        "id": "ykatVSEW2HvZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualização da Matriz de Confusão e das Medidas de Desempenho**\n",
        "\n",
        "Vamos agora verificar os dados de desempenho de cada um dos algoritmos juntamente com sua respectiva matriz de confusão."
      ],
      "metadata": {
        "id": "epK1fQzhGZHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# obtem as classes \n",
        "classesDataset = np.unique(Y_train)\n",
        "for i, methodName in enumerate(metodos):\n",
        "\n",
        "  Y_pred=confusao(methodName)\n",
        "  # obtem as classes \n",
        "  classesDataset = np.unique(Y_train)\n",
        "  \n",
        "# obtem a matriz de confusão\n",
        "  cm = skl.metrics.confusion_matrix(Y_test, Y_pred)\n",
        "\n",
        "# vamos plotar a matriz de confusao \n",
        "\n",
        "# definindo o tamanho da figura \n",
        "  plt.figure(figsize=(10,8))\n",
        "    \n",
        "# cria um mapa de cores dos valores da matriz de confusao\n",
        "  sns.heatmap(cm, xticklabels=classesDataset, yticklabels=classesDataset, cmap=\"YlGnBu\", annot=True)\n",
        "  sns.set(font_scale=1.1) # aumenta a escala das fontes do grafico\n",
        "        \n",
        "  plt.xlabel('Classes preditas')\n",
        "  plt.ylabel('Classes verdadeiras')\n",
        "  plt.title('Matriz de confusão  '+ methodName)\n",
        "  plt.show()\n",
        "  auxResults = relatorioDesempenho(Y_test, Y_pred, classesDataset, imprimeRelatorio=True)\n",
        "  print('------------------------------------------------------------------');\n",
        "  print('------------------------------------------------------------------');"
      ],
      "metadata": {
        "id": "8drBtqgS2rx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coxeXeY46Xgk"
      },
      "source": [
        "---\n",
        "## Conclusão\n",
        "\n",
        "Neste notebook, adicionamentos aos algoritmos K-NN e Naive Bayes, os algoritmos SVM de de indução de árvore de decisão, realizando as etapas de treinamento e teste utilizando o conjunto de dados iris. finalmente realizamos diversas medidas de desempenho para a avaliação dos resultados dos modelos. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "notebook_arvores_de_decisao_SVM_e_avaliacao_de_modelos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}